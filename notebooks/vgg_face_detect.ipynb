{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "sys.path.append('/home/arya_03/.envs/objdet/lib/python2.7/site-packages/')\n",
    "sys.path.append('/home/arya_03/.local/lib/python2.7/site-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.color import gray2rgb\n",
    "import cv2\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "from utils import create_fixed_image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Caffe input layer implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import cfg\n",
    "from plotting import plot_face_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net = caffe.Net('../trial.pt', caffe.TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "c = net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.blobs['data'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 20\n",
    "im = np.transpose(c['data'], [0, 2, 3, 1])[idx,...]\n",
    "plt.imshow(im)\n",
    "gt = c['gt_boxes'][idx, ...]\n",
    "print gt\n",
    "plt.figure()\n",
    "plot_face_bb(im, gt, path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with pretrained VGG Face model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_file = \"../data/VGG_FACE_deploy.prototxt\"\n",
    "weight_file = \"../data/VGG_FACE.caffemodel\"\n",
    "if (not os.path.exists(model_file)) or (not os.path.exists(weight_file)):\n",
    "    raise AttributeError(\"VGG_FACE prototxt (%s) and the caffemodel (%s) files are required\" % (\n",
    "        model_file, weight_file))\n",
    "if 'cpu' in theano.config.device:\n",
    "    print \"Caffe -- CPU mode\"\n",
    "    caffe.set_mode_cpu()\n",
    "else:\n",
    "    device = int(theano.config.device.split('gpu')[-1])\n",
    "    print \"Caffe -- GPU mode, device %d\" % device\n",
    "    caffe.set_mode_gpu()\n",
    "    caffe.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_net = caffe.Net(model_file, weight_file, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_net.blobs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imsize = (224, 224)\n",
    "res_size = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = imread('../test_imgs/j.jpg')\n",
    "img = create_fixed_image_shape(im, frame_size=res_size, mode='fit')\n",
    "crop_coord = int((res_size[0] - imsize[0]) / 2. + 0.5), int((res_size[1] - imsize[1]) / 2. + 0.5)\n",
    "\n",
    "img = img[crop_coord[0]:crop_coord[0]+imsize[0], crop_coord[1]:crop_coord[1]+imsize[1], :]\n",
    "plt.imshow(img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = np.transpose([img], [0, 3, 1, 2])\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_net.blobs['data'].reshape(*images.shape)\n",
    "vgg_net.blobs['data'].data[...] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = vgg_net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_net.blobs['pool4'].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "def plot_activation_matrix(Z, outname, save=True, ncols=10):\n",
    "    num = Z.shape[0]\n",
    "    fig = plt.figure(1, (80, 80))\n",
    "    fig.subplots_adjust(left=0.05, right=0.95)\n",
    "    grid = AxesGrid(fig, (1, 4, 2),  # similar to subplot(142)\n",
    "                    nrows_ncols=(int(np.ceil(num / (ncols))), ncols),\n",
    "                    axes_pad=0.04,\n",
    "                    share_all=True,\n",
    "                    label_mode=\"L\",\n",
    "                    )\n",
    "\n",
    "    for i in range(num):\n",
    "        im = grid[i].imshow(Z[i, ...], cmap='gray')\n",
    "    for i in range(grid.ngrids):\n",
    "        grid[i].axis('off')\n",
    "\n",
    "    for cax in grid.cbar_axes:\n",
    "        cax.toggle_label(False)\n",
    "    if save:\n",
    "        fig.savefig(outname, bbox_inches='tight')\n",
    "        fig.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['conv4_3'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['pool4'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['pool5'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['conv5_3'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['pool5'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['pool5'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_activation_matrix(vgg_net.blobs['pool5'].data[0, ...], '', save=False, ncols=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(vgg_net.blobs['conv5_3'].data[0, 0, ...], interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_file_list\n",
    "import glob\n",
    "from train_val_split import read_facescrub_img_list\n",
    "from plotting import plot_face_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder = '/media/shared/faceScrub/train_face_det/'\n",
    "path = folder\n",
    "actor_label_txt = '/media/shared/faceScrub/facescrub_actors.txt'\n",
    "actress_label_txt = '/media/shared/faceScrub/facescrub_actresses.txt'\n",
    "accept_pattern = '*/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnames, bboxes = read_facescrub_img_list(path, actor_label_txt, actress_label_txt, accept_pattern='*/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(fnames), len(bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_csv = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = read_csv(train_csv, sep='\\t')\n",
    "X = np.asarray(train_df['name'].as_matrix())\n",
    "y_str = train_df['bbox']\n",
    "y_l = map(lambda k: [np.float32(v)\n",
    "                     for v in k.split(',')], y_str)\n",
    "y = np.asarray(y_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_1 = X[1]\n",
    "y_1 = y[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im = imread(x_1)\n",
    "plot_face_bb(im, y_1, scale=False, path=False)\n",
    "img = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = (256, 256, 3)\n",
    "MAX_FACE_SIZE = 220\n",
    "MIN_FACE_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h0, w0, _ = img_size\n",
    "w1, h1, w2, h2 = y_1\n",
    "wc, hc = (y_1[0] + y_1[2]) / 2, (y_1[1] + y_1[3]) / 2\n",
    "face_width = (h2 - h1) / 2\n",
    "print \"Original center coords: (%.1f, %.1f)\" % (wc, hc)\n",
    "print \"Face coords: (%.1f, %.1f) (%.1f, %.1f) and face width: %.0f\" % (h1, w1, h2, w2, face_width * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Possible scales of computation\n",
    "high_scale = MAX_FACE_SIZE/2/face_width\n",
    "low_scale = MIN_FACE_SIZE/2/face_width\n",
    "print \"Scales of computation: %.3f - %.3f\" % (low_scale, high_scale)\n",
    "\n",
    "scale_comp = rng.choice(np.arange(low_scale, high_scale, (high_scale-low_scale)/100), 1)[0]\n",
    "new_face_width = round(face_width * scale_comp)\n",
    "swc, shc = round(wc * scale_comp), round(hc * scale_comp)\n",
    "sh1, sw1, sh2, sw2 = (shc-new_face_width, swc-new_face_width, \n",
    "                      shc+new_face_width, swc+new_face_width)\n",
    "print \"Chosen scale of computation: %.3f,\" % (scale_comp)\n",
    "print \"New face center: (%.1f, %.1f)\\nface width: %.0f\" % (\n",
    "    shc, swc, new_face_width * 2)\n",
    "res = cv2.resize(img, None, fx=scale_comp, fy=scale_comp)\n",
    "h, w, _ = res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Face width: %.1f\" % (new_face_width * 2)\n",
    "plot_face_bb(res[:,:,::-1], y_1*scale_comp, scale=False, path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Possible location of the face\n",
    "min_pad = new_face_width + 30\n",
    "lw, lh, hw, hh = (min(min_pad, w0 - min_pad), min(min_pad, h0 - min_pad), \n",
    "                  max(min_pad, w0 - min_pad), max(min_pad, h0 - min_pad))\n",
    "print \"Get face center in the given window: (%.1f, %.1f) (%.1f, %.1f)\" % (lh, lw, hh, hw)\n",
    "twc = rng.randint(lw, hw, 1)[0]\n",
    "thc = rng.randint(lh, hh, 1)[0]\n",
    "print \"New center location: (%.1f, %.1f)\" % (thc, twc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = np.random.randint(0, high=255, size=img_size).astype(np.uint8)\n",
    "sfh = shc - thc\n",
    "tfh = int(0 if sfh > 0 else abs(sfh))\n",
    "sfh = int(0 if sfh < 0 else sfh)\n",
    "sfw = swc - twc\n",
    "tfw = int(0 if sfw > 0 else abs(sfw))\n",
    "sfw = int(0 if sfw < 0 else sfw)\n",
    "print \"source begin: (%.0f, %.0f) target begin: (%.0f, %.0f)\" % (sfh, sfw, tfh, tfw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seh = shc - thc + h0\n",
    "teh = int(h0 if seh <= h else h0 - seh + h)\n",
    "seh = int(h if seh > h else seh)\n",
    "sew = swc - twc + w0\n",
    "tew = int(w0 if sew <= w else w0 - sew + w)\n",
    "sew = int(w if sew > w else sew)\n",
    "print \"source end: (%.0f, %.0f) target end: (%.0f, %.0f)\" % (seh, sew, teh, tew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ty_1 = np.array([twc-new_face_width, thc-new_face_width, twc+new_face_width, thc+new_face_width])\n",
    "out[tfh:teh, tfw:tew, :] = res[sfh:seh, sfw:sew, :]\n",
    "out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "plot_face_bb(out, ty_1, scale=False, path=False)\n",
    "print \"new face center: (%.0f, %.0f)\" % (thc, twc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in glob.glob('*.jpg'):\n",
    "    plt.figure()\n",
    "    plt.imshow(imread(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
